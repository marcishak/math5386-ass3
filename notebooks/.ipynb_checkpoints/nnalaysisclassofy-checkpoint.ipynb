{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def array(x):\n",
    "    return x\n",
    "def parse_list_col(x):\n",
    "    return eval(x)[0]\n",
    "def mean_list_col(x):\n",
    "    return pd.DataFrame(x.values.tolist()).apply(\"mean\", axis = 0).values.tolist()\n",
    "def std_list_col(x):\n",
    "    x =  pd.DataFrame(x.values.tolist()).apply(\"std\", axis = 0).values.tolist()\n",
    "    # print(x)\n",
    "    return x\n",
    "def upper_conf_list_col(x):\n",
    "    mean = mean_list_col(x)\n",
    "    std = std_list_col(x)\n",
    "    return (np.array(mean) + 1.96 * np.array(std)).tolist()\n",
    "def lower_conf_list_col(x):\n",
    "    mean = mean_list_col(x)\n",
    "    std = std_list_col(x)\n",
    "    return (np.array(mean) - 1.96 * np.array(std)).tolist()\n",
    "    \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/output/NNClassifier-nnsummary.csv\")\n",
    "df[\"fprs\"] = df[\"fprs\"].apply(parse_list_col)\n",
    "df[\"tprs\"] = df[\"tprs\"].apply(parse_list_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fprs</th>\n",
       "      <th>tprs</th>\n",
       "      <th>roc_auc_scores</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>opt_func</th>\n",
       "      <th>loss_func</th>\n",
       "      <th>hidden_layer_size</th>\n",
       "      <th>layers_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.663430</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.657695</td>\n",
       "      <td>0.645455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.664169</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.662320</td>\n",
       "      <td>0.641860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.660655</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.667869</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.664077</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.667129</td>\n",
       "      <td>0.660633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.664724</td>\n",
       "      <td>0.660633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.664447</td>\n",
       "      <td>0.651376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.675159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.675159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.662782</td>\n",
       "      <td>0.642202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.636330</td>\n",
       "      <td>0.652361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.599149</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.615659</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.645070</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.624491</td>\n",
       "      <td>0.606635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.656724</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.655614</td>\n",
       "      <td>0.612440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.664077</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.675159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.675159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.675159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.675159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>[0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...</td>\n",
       "      <td>[0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                               fprs  \\\n",
       "0            0  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "1            1  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "2            2  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "3            3  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "4            4  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "5            5  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "6            6  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "7            7  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "8            8  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "9            9  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "10          10  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "11          11  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "12          12  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "13          13  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "14          14  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "15          15  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "16          16  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "17          17  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "18          18  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "19          19  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "20          20  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "21          21  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "22          22  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "23          23  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "24          24  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "25          25  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "26          26  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "27          27  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "28          28  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "29          29  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "30          30  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "31          31  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "32          32  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "33          33  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "34          34  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "35          35  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "36          36  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "37          37  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "38          38  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "39          39  [0.0, 0.00980392, 0.00980392, 0.02941176, 0.02...   \n",
       "\n",
       "                                                 tprs  roc_auc_scores  \\\n",
       "0   [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.663430   \n",
       "1   [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.657695   \n",
       "2   [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.664169   \n",
       "3   [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.662320   \n",
       "4   [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.660655   \n",
       "5   [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.667869   \n",
       "6   [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.664077   \n",
       "7   [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.667129   \n",
       "8   [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.664724   \n",
       "9   [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.664447   \n",
       "10  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "11  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "12  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "13  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "14  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "15  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "16  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "17  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "18  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "19  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "20  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.662782   \n",
       "21  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.636330   \n",
       "22  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.599149   \n",
       "23  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.615659   \n",
       "24  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.645070   \n",
       "25  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.624491   \n",
       "26  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.656724   \n",
       "27  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.660377   \n",
       "28  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.655614   \n",
       "29  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.664077   \n",
       "30  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "31  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "32  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "33  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "34  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "35  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "36  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "37  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "38  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "39  [0.0, 0.0, 0.00943396, 0.00943396, 0.04716981,...        0.500000   \n",
       "\n",
       "    f1_scores  r2  mse opt_func           loss_func  hidden_layer_size  \\\n",
       "0    0.644860 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "1    0.645455 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "2    0.641509 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "3    0.641860 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "4    0.638889 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "5    0.622642 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "6    0.657658 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "7    0.660633 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "8    0.660633 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "9    0.651376 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "10   0.000000 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "11   0.000000 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "12   0.000000 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "13   0.000000 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "14   0.675159 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "15   0.000000 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "16   0.675159 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "17   0.000000 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "18   0.000000 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "19   0.000000 NaN  NaN     Adam  mean_squared_error                  5   \n",
       "20   0.642202 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "21   0.652361 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "22   0.644444 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "23   0.591549 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "24   0.584906 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "25   0.606635 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "26   0.660714 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "27   0.603774 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "28   0.612440 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "29   0.629630 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "30   0.000000 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "31   0.000000 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "32   0.000000 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "33   0.675159 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "34   0.675159 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "35   0.675159 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "36   0.000000 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "37   0.000000 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "38   0.675159 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "39   0.000000 NaN  NaN      SGD  mean_squared_error                  5   \n",
       "\n",
       "    layers_length  \n",
       "0               2  \n",
       "1               2  \n",
       "2               2  \n",
       "3               2  \n",
       "4               2  \n",
       "5               2  \n",
       "6               2  \n",
       "7               2  \n",
       "8               2  \n",
       "9               2  \n",
       "10              5  \n",
       "11              5  \n",
       "12              5  \n",
       "13              5  \n",
       "14              5  \n",
       "15              5  \n",
       "16              5  \n",
       "17              5  \n",
       "18              5  \n",
       "19              5  \n",
       "20              2  \n",
       "21              2  \n",
       "22              2  \n",
       "23              2  \n",
       "24              2  \n",
       "25              2  \n",
       "26              2  \n",
       "27              2  \n",
       "28              2  \n",
       "29              2  \n",
       "30              5  \n",
       "31              5  \n",
       "32              5  \n",
       "33              5  \n",
       "34              5  \n",
       "35              5  \n",
       "36              5  \n",
       "37              5  \n",
       "38              5  \n",
       "39              5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = df.groupby([\"opt_func\",\"loss_func\",\"hidden_layer_size\",\"layers_length\"]).agg(\n",
    "    mean_roc_auc_scores = (\"roc_auc_scores\",\"mean\"),\n",
    "    std_roc_auc_scores  = (\"roc_auc_scores\",\"std\"),\n",
    "    upper_conf_roc_auc_scores  = (\"roc_auc_scores\", lambda x: np.mean(x) + np.std(x)*1.96),\n",
    "    lower_conf_roc_auc_scores  = (\"roc_auc_scores\", lambda x: np.mean(x) - np.std(x)*1.96),\n",
    "    mean_f1_scores      = (\"f1_scores\",\"mean\"),\n",
    "    std_f1_scores       = (\"f1_scores\",\"std\"),\n",
    "    upper_conf_f1_scores  = (\"roc_auc_scores\", lambda x: np.mean(x) + np.std(x)*1.96),\n",
    "    lower_conf_f1_scores  = (\"roc_auc_scores\", lambda x: np.mean(x) - np.std(x)*1.96),\n",
    "    mean_fprs = (\"fprs\", mean_list_col),\n",
    "    std_fprs = (\"fprs\", std_list_col),\n",
    "    upper_conf_fprs = (\"fprs\", upper_conf_list_col),\n",
    "    lower_conf_fprs = (\"fprs\", lower_conf_list_col),\n",
    "    mean_tprs = (\"tprs\", mean_list_col),\n",
    "    std_tprs = (\"tprs\", std_list_col),\n",
    "    upper_conf_tprs = (\"tprs\", upper_conf_list_col),\n",
    "    lower_conf_tprs = (\"tprs\", lower_conf_list_col),\n",
    ").reset_index()\n",
    "# print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opt_func</th>\n",
       "      <th>loss_func</th>\n",
       "      <th>hidden_layer_size</th>\n",
       "      <th>layers_length</th>\n",
       "      <th>mean_roc_auc_scores</th>\n",
       "      <th>std_roc_auc_scores</th>\n",
       "      <th>upper_conf_roc_auc_scores</th>\n",
       "      <th>lower_conf_roc_auc_scores</th>\n",
       "      <th>mean_f1_scores</th>\n",
       "      <th>std_f1_scores</th>\n",
       "      <th>upper_conf_f1_scores</th>\n",
       "      <th>lower_conf_f1_scores</th>\n",
       "      <th>mean_fprs</th>\n",
       "      <th>std_fprs</th>\n",
       "      <th>upper_conf_fprs</th>\n",
       "      <th>lower_conf_fprs</th>\n",
       "      <th>mean_tprs</th>\n",
       "      <th>std_tprs</th>\n",
       "      <th>upper_conf_tprs</th>\n",
       "      <th>lower_conf_tprs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.663651</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.669139</td>\n",
       "      <td>0.658164</td>\n",
       "      <td>0.646552</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.669139</td>\n",
       "      <td>0.658164</td>\n",
       "      <td>[0.0, 0.009803919999999999, 0.0098039199999999...</td>\n",
       "      <td>[0.0, 1.828559098217032e-18, 1.828559098217032...</td>\n",
       "      <td>[0.0, 0.009803920000000002, 0.0098039200000000...</td>\n",
       "      <td>[0.0, 0.009803919999999995, 0.0098039199999999...</td>\n",
       "      <td>[0.0, 0.0, 0.009433960000000002, 0.00943396000...</td>\n",
       "      <td>[0.0, 0.0, 1.828559098217032e-18, 1.8285590982...</td>\n",
       "      <td>[0.0, 0.0, 0.009433960000000005, 0.00943396000...</td>\n",
       "      <td>[0.0, 0.0, 0.009433959999999998, 0.00943395999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adam</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.135032</td>\n",
       "      <td>0.284672</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[0.0, 0.009803919999999999, 0.0098039199999999...</td>\n",
       "      <td>[0.0, 1.828559098217032e-18, 1.828559098217032...</td>\n",
       "      <td>[0.0, 0.009803920000000002, 0.0098039200000000...</td>\n",
       "      <td>[0.0, 0.009803919999999995, 0.0098039199999999...</td>\n",
       "      <td>[0.0, 0.0, 0.009433960000000002, 0.00943396000...</td>\n",
       "      <td>[0.0, 0.0, 1.828559098217032e-18, 1.8285590982...</td>\n",
       "      <td>[0.0, 0.0, 0.009433960000000005, 0.00943396000...</td>\n",
       "      <td>[0.0, 0.0, 0.009433959999999998, 0.00943395999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.642027</td>\n",
       "      <td>0.022453</td>\n",
       "      <td>0.683777</td>\n",
       "      <td>0.600277</td>\n",
       "      <td>0.622865</td>\n",
       "      <td>0.026554</td>\n",
       "      <td>0.683777</td>\n",
       "      <td>0.600277</td>\n",
       "      <td>[0.0, 0.009803919999999999, 0.0098039199999999...</td>\n",
       "      <td>[0.0, 1.828559098217032e-18, 1.828559098217032...</td>\n",
       "      <td>[0.0, 0.009803920000000002, 0.0098039200000000...</td>\n",
       "      <td>[0.0, 0.009803919999999995, 0.0098039199999999...</td>\n",
       "      <td>[0.0, 0.0, 0.009433960000000002, 0.00943396000...</td>\n",
       "      <td>[0.0, 0.0, 1.828559098217032e-18, 1.8285590982...</td>\n",
       "      <td>[0.0, 0.0, 0.009433960000000005, 0.00943396000...</td>\n",
       "      <td>[0.0, 0.0, 0.009433959999999998, 0.00943395999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGD</td>\n",
       "      <td>mean_squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.270064</td>\n",
       "      <td>0.348651</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[0.0, 0.009803919999999999, 0.0098039199999999...</td>\n",
       "      <td>[0.0, 1.828559098217032e-18, 1.828559098217032...</td>\n",
       "      <td>[0.0, 0.009803920000000002, 0.0098039200000000...</td>\n",
       "      <td>[0.0, 0.009803919999999995, 0.0098039199999999...</td>\n",
       "      <td>[0.0, 0.0, 0.009433960000000002, 0.00943396000...</td>\n",
       "      <td>[0.0, 0.0, 1.828559098217032e-18, 1.8285590982...</td>\n",
       "      <td>[0.0, 0.0, 0.009433960000000005, 0.00943396000...</td>\n",
       "      <td>[0.0, 0.0, 0.009433959999999998, 0.00943395999...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  opt_func           loss_func  hidden_layer_size  layers_length  \\\n",
       "0     Adam  mean_squared_error                  5              2   \n",
       "1     Adam  mean_squared_error                  5              5   \n",
       "2      SGD  mean_squared_error                  5              2   \n",
       "3      SGD  mean_squared_error                  5              5   \n",
       "\n",
       "   mean_roc_auc_scores  std_roc_auc_scores  upper_conf_roc_auc_scores  \\\n",
       "0             0.663651            0.002951                   0.669139   \n",
       "1             0.500000            0.000000                   0.500000   \n",
       "2             0.642027            0.022453                   0.683777   \n",
       "3             0.500000            0.000000                   0.500000   \n",
       "\n",
       "   lower_conf_roc_auc_scores  mean_f1_scores  std_f1_scores  \\\n",
       "0                   0.658164        0.646552       0.011667   \n",
       "1                   0.500000        0.135032       0.284672   \n",
       "2                   0.600277        0.622865       0.026554   \n",
       "3                   0.500000        0.270064       0.348651   \n",
       "\n",
       "   upper_conf_f1_scores  lower_conf_f1_scores  \\\n",
       "0              0.669139              0.658164   \n",
       "1              0.500000              0.500000   \n",
       "2              0.683777              0.600277   \n",
       "3              0.500000              0.500000   \n",
       "\n",
       "                                           mean_fprs  \\\n",
       "0  [0.0, 0.009803919999999999, 0.0098039199999999...   \n",
       "1  [0.0, 0.009803919999999999, 0.0098039199999999...   \n",
       "2  [0.0, 0.009803919999999999, 0.0098039199999999...   \n",
       "3  [0.0, 0.009803919999999999, 0.0098039199999999...   \n",
       "\n",
       "                                            std_fprs  \\\n",
       "0  [0.0, 1.828559098217032e-18, 1.828559098217032...   \n",
       "1  [0.0, 1.828559098217032e-18, 1.828559098217032...   \n",
       "2  [0.0, 1.828559098217032e-18, 1.828559098217032...   \n",
       "3  [0.0, 1.828559098217032e-18, 1.828559098217032...   \n",
       "\n",
       "                                     upper_conf_fprs  \\\n",
       "0  [0.0, 0.009803920000000002, 0.0098039200000000...   \n",
       "1  [0.0, 0.009803920000000002, 0.0098039200000000...   \n",
       "2  [0.0, 0.009803920000000002, 0.0098039200000000...   \n",
       "3  [0.0, 0.009803920000000002, 0.0098039200000000...   \n",
       "\n",
       "                                     lower_conf_fprs  \\\n",
       "0  [0.0, 0.009803919999999995, 0.0098039199999999...   \n",
       "1  [0.0, 0.009803919999999995, 0.0098039199999999...   \n",
       "2  [0.0, 0.009803919999999995, 0.0098039199999999...   \n",
       "3  [0.0, 0.009803919999999995, 0.0098039199999999...   \n",
       "\n",
       "                                           mean_tprs  \\\n",
       "0  [0.0, 0.0, 0.009433960000000002, 0.00943396000...   \n",
       "1  [0.0, 0.0, 0.009433960000000002, 0.00943396000...   \n",
       "2  [0.0, 0.0, 0.009433960000000002, 0.00943396000...   \n",
       "3  [0.0, 0.0, 0.009433960000000002, 0.00943396000...   \n",
       "\n",
       "                                            std_tprs  \\\n",
       "0  [0.0, 0.0, 1.828559098217032e-18, 1.8285590982...   \n",
       "1  [0.0, 0.0, 1.828559098217032e-18, 1.8285590982...   \n",
       "2  [0.0, 0.0, 1.828559098217032e-18, 1.8285590982...   \n",
       "3  [0.0, 0.0, 1.828559098217032e-18, 1.8285590982...   \n",
       "\n",
       "                                     upper_conf_tprs  \\\n",
       "0  [0.0, 0.0, 0.009433960000000005, 0.00943396000...   \n",
       "1  [0.0, 0.0, 0.009433960000000005, 0.00943396000...   \n",
       "2  [0.0, 0.0, 0.009433960000000005, 0.00943396000...   \n",
       "3  [0.0, 0.0, 0.009433960000000005, 0.00943396000...   \n",
       "\n",
       "                                     lower_conf_tprs  \n",
       "0  [0.0, 0.0, 0.009433959999999998, 0.00943395999...  \n",
       "1  [0.0, 0.0, 0.009433959999999998, 0.00943395999...  \n",
       "2  [0.0, 0.0, 0.009433959999999998, 0.00943395999...  \n",
       "3  [0.0, 0.0, 0.009433959999999998, 0.00943395999...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrr}\n",
      "\\toprule\n",
      "{} & Optimisation Function & Neurons Per Hidden Layer & Hidden Layers & Mean ROC-AUC Score & ROC-AUC Score Std. dev & ROC-AUC Score Upper 95\\% CI & ROC-AUC Score Lower 95\\% CI \\\\\n",
      "\\midrule\n",
      "0 &                  Adam &                        5 &             2 &           0.663651 &               0.002951 &                   0.669139 &                   0.658164 \\\\\n",
      "1 &                  Adam &                        5 &             5 &           0.500000 &               0.000000 &                   0.500000 &                   0.500000 \\\\\n",
      "2 &                   SGD &                        5 &             2 &           0.642027 &               0.022453 &                   0.683777 &                   0.600277 \\\\\n",
      "3 &                   SGD &                        5 &             5 &           0.500000 &               0.000000 &                   0.500000 &                   0.500000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary_df[[\"opt_func\",\"hidden_layer_size\",\"layers_length\",\"mean_roc_auc_scores\",\"std_roc_auc_scores\",\"upper_conf_roc_auc_scores\",\"lower_conf_roc_auc_scores\"]].to_latex(header = [\"Optimisation Function\", \n",
    "\"Neurons Per Hidden Layer\", \n",
    "\"Hidden Layers\", \n",
    "\"Mean ROC-AUC Score\",\n",
    "\"ROC-AUC Score Std. dev\", \n",
    "\"ROC-AUC Score Upper 95% CI\", \n",
    "\"ROC-AUC Score Lower 95% CI\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrr}\n",
      "\\toprule\n",
      "{} & Optimisation Function & Neurons Per Hidden Layer & Hidden Layers & Mean F1 Score & F1 Score Std. dev & F1 Score Upper 95\\% CI & F1 Score Lower 95\\% CI \\\\\n",
      "\\midrule\n",
      "0 &                  Adam &                        5 &             2 &      0.646552 &          0.011667 &              0.669139 &              0.658164 \\\\\n",
      "1 &                  Adam &                        5 &             5 &      0.135032 &          0.284672 &              0.500000 &              0.500000 \\\\\n",
      "2 &                   SGD &                        5 &             2 &      0.622865 &          0.026554 &              0.683777 &              0.600277 \\\\\n",
      "3 &                   SGD &                        5 &             5 &      0.270064 &          0.348651 &              0.500000 &              0.500000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary_df[[\"opt_func\",\"hidden_layer_size\",\"layers_length\",\"mean_f1_scores\",\"std_f1_scores\",\"upper_conf_f1_scores\",\"lower_conf_f1_scores\"]].to_latex(header = [\"Optimisation Function\", \n",
    "\"Neurons Hidden Layer\", \n",
    "\"Hidden Layers\", \n",
    "\"Mean F1 Score\",\n",
    "\"F1 Score Std. dev\", \n",
    "\"F1 Score Upper 95% CI\", \n",
    "\"F1 Score Lower 95% CI\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.009803919999999999, 0.009803919999999999, 0.029411760000000002, 0.029411760000000002, 0.039215690000000004, 0.039215690000000004, 0.04901961, 0.04901961, 0.06862745000000002, 0.06862745000000002, 0.07843137, 0.07843137, 0.08823528999999998, 0.08823528999999998, 0.09803922, 0.09803922, 0.10784313999999998, 0.10784313999999998, 0.12745097999999996, 0.12745097999999996, 0.18627451000000003, 0.18627451000000003, 0.20588235, 0.20588235, 0.21568627, 0.21568627, 0.2254902, 0.2254902, 0.24509803999999996, 0.24509803999999996, 0.2549019599999999, 0.2549019599999999, 0.26470588000000006, 0.26470588000000006, 0.28431373, 0.28431373, 0.29411765, 0.29411765, 0.30392157, 0.30392157, 0.31372549, 0.31372549, 0.34313724999999995, 0.34313724999999995, 0.3529411800000001, 0.3529411800000001, 0.36274510000000004, 0.36274510000000004, 0.37254902000000006, 0.37254902000000006, 0.40196078, 0.40196078, 0.44117646999999993, 0.44117646999999993, 0.4509803899999999, 0.4509803899999999, 0.47058824, 0.47058824, 0.48039215999999996, 0.48039215999999996, 0.4901960799999999, 0.4901960799999999, 0.51960784, 0.51960784, 0.5294117600000001, 0.5294117600000001, 0.5588235299999998, 0.5588235299999998, 0.56862745, 0.56862745, 0.5980392200000001, 0.5980392200000001, 0.6372549000000001, 0.6372549000000001, 0.6470588199999999, 0.6470588199999999, 0.65686275, 0.65686275, 0.6666666699999999, 0.6666666699999999, 0.6862745099999998, 0.6862745099999998, 0.71568627, 0.71568627, 0.7254902000000001, 0.7254902000000001, 0.7647058800000001, 0.7647058800000001, 0.7745097999999999, 0.7745097999999999, 0.7941176500000001, 0.7941176500000001, 0.8333333300000001, 0.8333333300000001, 0.9019607799999998, 0.9019607799999998, 0.94117647, 0.94117647, 1.0]\n",
      "[0.0, 0.0, 0.009433960000000002, 0.009433960000000002, 0.04716980999999999, 0.04716980999999999, 0.11320755000000002, 0.11320755000000002, 0.12264150999999998, 0.12264150999999998, 0.13207547, 0.13207547, 0.16037736, 0.16037736, 0.19811321, 0.19811321, 0.21698113000000002, 0.21698113000000002, 0.22641509, 0.22641509, 0.29245283000000005, 0.29245283000000005, 0.32075472, 0.32075472, 0.3490566, 0.3490566, 0.35849056999999995, 0.35849056999999995, 0.38679245000000007, 0.38679245000000007, 0.40566037999999993, 0.40566037999999993, 0.41509434, 0.41509434, 0.43396226000000004, 0.43396226000000004, 0.4622641500000001, 0.4622641500000001, 0.4905660399999999, 0.4905660399999999, 0.5754716999999999, 0.5754716999999999, 0.5849056600000001, 0.5849056600000001, 0.6132075500000002, 0.6132075500000002, 0.6320754700000001, 0.6320754700000001, 0.64150943, 0.64150943, 0.6509434, 0.6509434, 0.66037736, 0.66037736, 0.66981132, 0.66981132, 0.68867925, 0.68867925, 0.7075471699999999, 0.7075471699999999, 0.7264150899999999, 0.7264150899999999, 0.7358490599999999, 0.7358490599999999, 0.7735849100000001, 0.7735849100000001, 0.7924528300000001, 0.7924528300000001, 0.80188679, 0.80188679, 0.82075472, 0.82075472, 0.8490566000000002, 0.8490566000000002, 0.8584905700000001, 0.8584905700000001, 0.86792453, 0.86792453, 0.88679245, 0.88679245, 0.9056603800000003, 0.9056603800000003, 0.9150943399999998, 0.9150943399999998, 0.9245283000000002, 0.9245283000000002, 0.93396226, 0.93396226, 0.94339623, 0.94339623, 0.95283019, 0.95283019, 0.96226415, 0.96226415, 0.97169811, 0.97169811, 0.9811320799999999, 0.9811320799999999, 1.0, 1.0]\n",
      "[0.0, 0.009803919999999999, 0.009803919999999999, 0.029411760000000002, 0.029411760000000002, 0.039215690000000004, 0.039215690000000004, 0.04901961, 0.04901961, 0.06862745000000002, 0.06862745000000002, 0.07843137, 0.07843137, 0.08823528999999998, 0.08823528999999998, 0.09803922, 0.09803922, 0.10784313999999998, 0.10784313999999998, 0.12745097999999996, 0.12745097999999996, 0.18627451000000003, 0.18627451000000003, 0.20588235, 0.20588235, 0.21568627, 0.21568627, 0.2254902, 0.2254902, 0.24509803999999996, 0.24509803999999996, 0.2549019599999999, 0.2549019599999999, 0.26470588000000006, 0.26470588000000006, 0.28431373, 0.28431373, 0.29411765, 0.29411765, 0.30392157, 0.30392157, 0.31372549, 0.31372549, 0.34313724999999995, 0.34313724999999995, 0.3529411800000001, 0.3529411800000001, 0.36274510000000004, 0.36274510000000004, 0.37254902000000006, 0.37254902000000006, 0.40196078, 0.40196078, 0.44117646999999993, 0.44117646999999993, 0.4509803899999999, 0.4509803899999999, 0.47058824, 0.47058824, 0.48039215999999996, 0.48039215999999996, 0.4901960799999999, 0.4901960799999999, 0.51960784, 0.51960784, 0.5294117600000001, 0.5294117600000001, 0.5588235299999998, 0.5588235299999998, 0.56862745, 0.56862745, 0.5980392200000001, 0.5980392200000001, 0.6372549000000001, 0.6372549000000001, 0.6470588199999999, 0.6470588199999999, 0.65686275, 0.65686275, 0.6666666699999999, 0.6666666699999999, 0.6862745099999998, 0.6862745099999998, 0.71568627, 0.71568627, 0.7254902000000001, 0.7254902000000001, 0.7647058800000001, 0.7647058800000001, 0.7745097999999999, 0.7745097999999999, 0.7941176500000001, 0.7941176500000001, 0.8333333300000001, 0.8333333300000001, 0.9019607799999998, 0.9019607799999998, 0.94117647, 0.94117647, 1.0]\n",
      "[0.0, 0.0, 0.009433960000000002, 0.009433960000000002, 0.04716980999999999, 0.04716980999999999, 0.11320755000000002, 0.11320755000000002, 0.12264150999999998, 0.12264150999999998, 0.13207547, 0.13207547, 0.16037736, 0.16037736, 0.19811321, 0.19811321, 0.21698113000000002, 0.21698113000000002, 0.22641509, 0.22641509, 0.29245283000000005, 0.29245283000000005, 0.32075472, 0.32075472, 0.3490566, 0.3490566, 0.35849056999999995, 0.35849056999999995, 0.38679245000000007, 0.38679245000000007, 0.40566037999999993, 0.40566037999999993, 0.41509434, 0.41509434, 0.43396226000000004, 0.43396226000000004, 0.4622641500000001, 0.4622641500000001, 0.4905660399999999, 0.4905660399999999, 0.5754716999999999, 0.5754716999999999, 0.5849056600000001, 0.5849056600000001, 0.6132075500000002, 0.6132075500000002, 0.6320754700000001, 0.6320754700000001, 0.64150943, 0.64150943, 0.6509434, 0.6509434, 0.66037736, 0.66037736, 0.66981132, 0.66981132, 0.68867925, 0.68867925, 0.7075471699999999, 0.7075471699999999, 0.7264150899999999, 0.7264150899999999, 0.7358490599999999, 0.7358490599999999, 0.7735849100000001, 0.7735849100000001, 0.7924528300000001, 0.7924528300000001, 0.80188679, 0.80188679, 0.82075472, 0.82075472, 0.8490566000000002, 0.8490566000000002, 0.8584905700000001, 0.8584905700000001, 0.86792453, 0.86792453, 0.88679245, 0.88679245, 0.9056603800000003, 0.9056603800000003, 0.9150943399999998, 0.9150943399999998, 0.9245283000000002, 0.9245283000000002, 0.93396226, 0.93396226, 0.94339623, 0.94339623, 0.95283019, 0.95283019, 0.96226415, 0.96226415, 0.97169811, 0.97169811, 0.9811320799999999, 0.9811320799999999, 1.0, 1.0]\n",
      "[0.0, 0.009803919999999999, 0.009803919999999999, 0.029411760000000002, 0.029411760000000002, 0.039215690000000004, 0.039215690000000004, 0.04901961, 0.04901961, 0.06862745000000002, 0.06862745000000002, 0.07843137, 0.07843137, 0.08823528999999998, 0.08823528999999998, 0.09803922, 0.09803922, 0.10784313999999998, 0.10784313999999998, 0.12745097999999996, 0.12745097999999996, 0.18627451000000003, 0.18627451000000003, 0.20588235, 0.20588235, 0.21568627, 0.21568627, 0.2254902, 0.2254902, 0.24509803999999996, 0.24509803999999996, 0.2549019599999999, 0.2549019599999999, 0.26470588000000006, 0.26470588000000006, 0.28431373, 0.28431373, 0.29411765, 0.29411765, 0.30392157, 0.30392157, 0.31372549, 0.31372549, 0.34313724999999995, 0.34313724999999995, 0.3529411800000001, 0.3529411800000001, 0.36274510000000004, 0.36274510000000004, 0.37254902000000006, 0.37254902000000006, 0.40196078, 0.40196078, 0.44117646999999993, 0.44117646999999993, 0.4509803899999999, 0.4509803899999999, 0.47058824, 0.47058824, 0.48039215999999996, 0.48039215999999996, 0.4901960799999999, 0.4901960799999999, 0.51960784, 0.51960784, 0.5294117600000001, 0.5294117600000001, 0.5588235299999998, 0.5588235299999998, 0.56862745, 0.56862745, 0.5980392200000001, 0.5980392200000001, 0.6372549000000001, 0.6372549000000001, 0.6470588199999999, 0.6470588199999999, 0.65686275, 0.65686275, 0.6666666699999999, 0.6666666699999999, 0.6862745099999998, 0.6862745099999998, 0.71568627, 0.71568627, 0.7254902000000001, 0.7254902000000001, 0.7647058800000001, 0.7647058800000001, 0.7745097999999999, 0.7745097999999999, 0.7941176500000001, 0.7941176500000001, 0.8333333300000001, 0.8333333300000001, 0.9019607799999998, 0.9019607799999998, 0.94117647, 0.94117647, 1.0]\n",
      "[0.0, 0.0, 0.009433960000000002, 0.009433960000000002, 0.04716980999999999, 0.04716980999999999, 0.11320755000000002, 0.11320755000000002, 0.12264150999999998, 0.12264150999999998, 0.13207547, 0.13207547, 0.16037736, 0.16037736, 0.19811321, 0.19811321, 0.21698113000000002, 0.21698113000000002, 0.22641509, 0.22641509, 0.29245283000000005, 0.29245283000000005, 0.32075472, 0.32075472, 0.3490566, 0.3490566, 0.35849056999999995, 0.35849056999999995, 0.38679245000000007, 0.38679245000000007, 0.40566037999999993, 0.40566037999999993, 0.41509434, 0.41509434, 0.43396226000000004, 0.43396226000000004, 0.4622641500000001, 0.4622641500000001, 0.4905660399999999, 0.4905660399999999, 0.5754716999999999, 0.5754716999999999, 0.5849056600000001, 0.5849056600000001, 0.6132075500000002, 0.6132075500000002, 0.6320754700000001, 0.6320754700000001, 0.64150943, 0.64150943, 0.6509434, 0.6509434, 0.66037736, 0.66037736, 0.66981132, 0.66981132, 0.68867925, 0.68867925, 0.7075471699999999, 0.7075471699999999, 0.7264150899999999, 0.7264150899999999, 0.7358490599999999, 0.7358490599999999, 0.7735849100000001, 0.7735849100000001, 0.7924528300000001, 0.7924528300000001, 0.80188679, 0.80188679, 0.82075472, 0.82075472, 0.8490566000000002, 0.8490566000000002, 0.8584905700000001, 0.8584905700000001, 0.86792453, 0.86792453, 0.88679245, 0.88679245, 0.9056603800000003, 0.9056603800000003, 0.9150943399999998, 0.9150943399999998, 0.9245283000000002, 0.9245283000000002, 0.93396226, 0.93396226, 0.94339623, 0.94339623, 0.95283019, 0.95283019, 0.96226415, 0.96226415, 0.97169811, 0.97169811, 0.9811320799999999, 0.9811320799999999, 1.0, 1.0]\n",
      "[0.0, 0.009803919999999999, 0.009803919999999999, 0.029411760000000002, 0.029411760000000002, 0.039215690000000004, 0.039215690000000004, 0.04901961, 0.04901961, 0.06862745000000002, 0.06862745000000002, 0.07843137, 0.07843137, 0.08823528999999998, 0.08823528999999998, 0.09803922, 0.09803922, 0.10784313999999998, 0.10784313999999998, 0.12745097999999996, 0.12745097999999996, 0.18627451000000003, 0.18627451000000003, 0.20588235, 0.20588235, 0.21568627, 0.21568627, 0.2254902, 0.2254902, 0.24509803999999996, 0.24509803999999996, 0.2549019599999999, 0.2549019599999999, 0.26470588000000006, 0.26470588000000006, 0.28431373, 0.28431373, 0.29411765, 0.29411765, 0.30392157, 0.30392157, 0.31372549, 0.31372549, 0.34313724999999995, 0.34313724999999995, 0.3529411800000001, 0.3529411800000001, 0.36274510000000004, 0.36274510000000004, 0.37254902000000006, 0.37254902000000006, 0.40196078, 0.40196078, 0.44117646999999993, 0.44117646999999993, 0.4509803899999999, 0.4509803899999999, 0.47058824, 0.47058824, 0.48039215999999996, 0.48039215999999996, 0.4901960799999999, 0.4901960799999999, 0.51960784, 0.51960784, 0.5294117600000001, 0.5294117600000001, 0.5588235299999998, 0.5588235299999998, 0.56862745, 0.56862745, 0.5980392200000001, 0.5980392200000001, 0.6372549000000001, 0.6372549000000001, 0.6470588199999999, 0.6470588199999999, 0.65686275, 0.65686275, 0.6666666699999999, 0.6666666699999999, 0.6862745099999998, 0.6862745099999998, 0.71568627, 0.71568627, 0.7254902000000001, 0.7254902000000001, 0.7647058800000001, 0.7647058800000001, 0.7745097999999999, 0.7745097999999999, 0.7941176500000001, 0.7941176500000001, 0.8333333300000001, 0.8333333300000001, 0.9019607799999998, 0.9019607799999998, 0.94117647, 0.94117647, 1.0]\n",
      "[0.0, 0.0, 0.009433960000000002, 0.009433960000000002, 0.04716980999999999, 0.04716980999999999, 0.11320755000000002, 0.11320755000000002, 0.12264150999999998, 0.12264150999999998, 0.13207547, 0.13207547, 0.16037736, 0.16037736, 0.19811321, 0.19811321, 0.21698113000000002, 0.21698113000000002, 0.22641509, 0.22641509, 0.29245283000000005, 0.29245283000000005, 0.32075472, 0.32075472, 0.3490566, 0.3490566, 0.35849056999999995, 0.35849056999999995, 0.38679245000000007, 0.38679245000000007, 0.40566037999999993, 0.40566037999999993, 0.41509434, 0.41509434, 0.43396226000000004, 0.43396226000000004, 0.4622641500000001, 0.4622641500000001, 0.4905660399999999, 0.4905660399999999, 0.5754716999999999, 0.5754716999999999, 0.5849056600000001, 0.5849056600000001, 0.6132075500000002, 0.6132075500000002, 0.6320754700000001, 0.6320754700000001, 0.64150943, 0.64150943, 0.6509434, 0.6509434, 0.66037736, 0.66037736, 0.66981132, 0.66981132, 0.68867925, 0.68867925, 0.7075471699999999, 0.7075471699999999, 0.7264150899999999, 0.7264150899999999, 0.7358490599999999, 0.7358490599999999, 0.7735849100000001, 0.7735849100000001, 0.7924528300000001, 0.7924528300000001, 0.80188679, 0.80188679, 0.82075472, 0.82075472, 0.8490566000000002, 0.8490566000000002, 0.8584905700000001, 0.8584905700000001, 0.86792453, 0.86792453, 0.88679245, 0.88679245, 0.9056603800000003, 0.9056603800000003, 0.9150943399999998, 0.9150943399999998, 0.9245283000000002, 0.9245283000000002, 0.93396226, 0.93396226, 0.94339623, 0.94339623, 0.95283019, 0.95283019, 0.96226415, 0.96226415, 0.97169811, 0.97169811, 0.9811320799999999, 0.9811320799999999, 1.0, 1.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    plt.clf()\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"\")\n",
    "    for _, row in summary_df.iterrows():\n",
    "#         print(row[\"hidden_layer_size\"])\n",
    "        print(row[\"mean_fprs\"])\n",
    "        print(row[\"mean_tprs\"])\n",
    "        fpr = row[\"mean_fprs\"]\n",
    "        tpr = row[\"mean_tprs\"]\n",
    "#         fpr = row[\"fprs\"]\n",
    "#         tpr = row[\"tprs\"]\n",
    "#         print(type(fpr))\n",
    "        h_size = row[\"hidden_layer_size\"]\n",
    "        layers_length = row[\"layers_length\"]\n",
    "        opt_func = row[\"opt_func\"]\n",
    "        lbl=f\"{h_size} x {layers_length} - {opt_func}\"\n",
    "#         print(lbl)\n",
    "        plt.plot(\n",
    "            fpr,\n",
    "            tpr,\n",
    "            linestyle=\"-\",\n",
    "            label=lbl, \n",
    "            alpha = 0.3\n",
    "    )\n",
    "    tlt = f\"ROC of {x} layer NN\"\n",
    "    plt.title(tlt)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}         & roc\\_auc\\_scores & \\textbf{  R-squared:         } &     0.976   \\\\\n",
      "\\textbf{Model:}                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.975   \\\\\n",
      "\\textbf{Method:}                &  Least Squares   & \\textbf{  F-statistic:       } &     750.8   \\\\\n",
      "\\textbf{Date:}                  & Wed, 18 Nov 2020 & \\textbf{  Prob (F-statistic):} &  1.12e-30   \\\\\n",
      "\\textbf{Time:}                  &     14:15:16     & \\textbf{  Log-Likelihood:    } &    120.07   \\\\\n",
      "\\textbf{No. Observations:}      &          40      & \\textbf{  AIC:               } &    -234.1   \\\\\n",
      "\\textbf{Df Residuals:}          &          37      & \\textbf{  BIC:               } &    -229.1   \\\\\n",
      "\\textbf{Df Model:}              &           2      & \\textbf{                     } &             \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{Intercept}              &       0.6582  &        0.003     &   192.228  &         0.000        &        0.651    &        0.665     \\\\\n",
      "\\textbf{C(layers\\_length)[T.5]} &      -0.1528  &        0.004     &   -38.654  &         0.000        &       -0.161    &       -0.145     \\\\\n",
      "\\textbf{opt\\_func[T.SGD]}       &      -0.0108  &        0.004     &    -2.734  &         0.010        &       -0.019    &       -0.003     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lclc}\n",
      "\\textbf{Omnibus:}       & 32.129 & \\textbf{  Durbin-Watson:     } &    0.976  \\\\\n",
      "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   75.535  \\\\\n",
      "\\textbf{Skew:}          & -2.065 & \\textbf{  Prob(JB):          } & 3.96e-17  \\\\\n",
      "\\textbf{Kurtosis:}      &  8.317 & \\textbf{  Cond. No.          } &     3.19  \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{OLS Regression Results}\n",
      "\\end{center}\n",
      "\n",
      "Notes: \\newline\n",
      " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>roc_auc_scores</td>  <th>  R-squared:         </th> <td>   0.976</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   750.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 18 Nov 2020</td> <th>  Prob (F-statistic):</th> <td>1.12e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:15:16</td>     <th>  Log-Likelihood:    </th> <td>  120.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    40</td>      <th>  AIC:               </th> <td>  -234.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    37</td>      <th>  BIC:               </th> <td>  -229.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>             <td>    0.6582</td> <td>    0.003</td> <td>  192.228</td> <td> 0.000</td> <td>    0.651</td> <td>    0.665</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(layers_length)[T.5]</th> <td>   -0.1528</td> <td>    0.004</td> <td>  -38.654</td> <td> 0.000</td> <td>   -0.161</td> <td>   -0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>opt_func[T.SGD]</th>       <td>   -0.0108</td> <td>    0.004</td> <td>   -2.734</td> <td> 0.010</td> <td>   -0.019</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>32.129</td> <th>  Durbin-Watson:     </th> <td>   0.976</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  75.535</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-2.065</td> <th>  Prob(JB):          </th> <td>3.96e-17</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.317</td> <th>  Cond. No.          </th> <td>    3.19</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         roc_auc_scores   R-squared:                       0.976\n",
       "Model:                            OLS   Adj. R-squared:                  0.975\n",
       "Method:                 Least Squares   F-statistic:                     750.8\n",
       "Date:                Wed, 18 Nov 2020   Prob (F-statistic):           1.12e-30\n",
       "Time:                        14:15:16   Log-Likelihood:                 120.07\n",
       "No. Observations:                  40   AIC:                            -234.1\n",
       "Df Residuals:                      37   BIC:                            -229.1\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================\n",
       "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "Intercept                 0.6582      0.003    192.228      0.000       0.651       0.665\n",
       "C(layers_length)[T.5]    -0.1528      0.004    -38.654      0.000      -0.161      -0.145\n",
       "opt_func[T.SGD]          -0.0108      0.004     -2.734      0.010      -0.019      -0.003\n",
       "==============================================================================\n",
       "Omnibus:                       32.129   Durbin-Watson:                   0.976\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               75.535\n",
       "Skew:                          -2.065   Prob(JB):                     3.96e-17\n",
       "Kurtosis:                       8.317   Cond. No.                         3.19\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_df_model = df[[\"roc_auc_scores\",\"opt_func\",\"loss_func\", \"hidden_layer_size\",\"layers_length\"]]\n",
    "mod = smf.ols(formula='roc_auc_scores ~ C(layers_length) + C(hidden_layer_size) + loss_func + opt_func', data=summary_df_model)\n",
    "res = mod.fit()\n",
    "print(res.summary().as_latex())\n",
    "fig = sm.graphics.plot_partregress_grid(res)\n",
    "fig.tight_layout(pad=1.0)\n",
    "res.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
